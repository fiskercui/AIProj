# GPU è®¾ç½®æŒ‡å—

å¦‚æœä½ åœ¨è¿è¡Œæµ‹è¯•æ—¶çœ‹åˆ° "âœ— æœªæ£€æµ‹åˆ° GPUï¼Œè·³è¿‡æ­¤æµ‹è¯•"ï¼Œè¿™ä¸ªæŒ‡å—å°†å¸®ä½ å¯ç”¨ GPU åŠ é€Ÿã€‚

## ğŸ“‹ å‰ææ¡ä»¶æ£€æŸ¥

### ç¬¬ä¸€æ­¥ï¼šç¡®è®¤ä½ æœ‰ NVIDIA GPU

1. **æ‰“å¼€è®¾å¤‡ç®¡ç†å™¨**ï¼ˆWindows ç³»ç»Ÿï¼‰
   - æŒ‰ `Win + X`ï¼Œé€‰æ‹©"è®¾å¤‡ç®¡ç†å™¨"
   - å±•å¼€"æ˜¾ç¤ºé€‚é…å™¨"

2. **æŸ¥çœ‹æ˜¾å¡å‹å·**
   - å¦‚æœçœ‹åˆ° NVIDIA GeForce / RTX / GTX / Quadro â†’ âœ… ç»§ç»­
   - å¦‚æœåªçœ‹åˆ° Intel / AMD â†’ âŒ æ— æ³•ä½¿ç”¨ CUDA

### ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥å½“å‰ PyTorch ç‰ˆæœ¬

è¿è¡Œå‘½ä»¤ï¼š
```bash
python -c "import torch; print('PyTorch ç‰ˆæœ¬:', torch.__version__); print('CUDA å¯ç”¨:', torch.cuda.is_available())"
```

**å¦‚æœè¾“å‡ºï¼š**
```
PyTorch ç‰ˆæœ¬: 2.x.x+cpu
CUDA å¯ç”¨: False
```
è¯´æ˜å®‰è£…çš„æ˜¯ **CPU ç‰ˆæœ¬**ï¼Œéœ€è¦é‡æ–°å®‰è£…ã€‚

---

## ğŸ”§ è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ Aï¼šé‡æ–°å®‰è£… GPU ç‰ˆæœ¬çš„ PyTorchï¼ˆæ¨èï¼‰

#### 1. å¸è½½å½“å‰ PyTorch
```bash
pip uninstall torch torchvision torchaudio
```

#### 2. ç¡®è®¤ CUDA ç‰ˆæœ¬

**æ–¹æ³• 1ï¼šä½¿ç”¨ nvidia-smi å‘½ä»¤**
```bash
nvidia-smi
```
æŸ¥çœ‹å³ä¸Šè§’çš„ CUDA Versionï¼ˆä¾‹å¦‚ï¼š12.1ï¼‰

**æ–¹æ³• 2ï¼šå¦‚æœæ²¡æœ‰ nvidia-smi**
- è®¿é—® [NVIDIA é©±åŠ¨ä¸‹è½½é¡µé¢](https://www.nvidia.com/Download/index.aspx)
- ä¸‹è½½å¹¶å®‰è£…æœ€æ–°é©±åŠ¨

#### 3. å®‰è£…å¯¹åº”ç‰ˆæœ¬çš„ PyTorch

è®¿é—® [PyTorch å®˜ç½‘](https://pytorch.org/get-started/locally/)ï¼Œæˆ–ç›´æ¥ä½¿ç”¨ï¼š

**CUDA 12.1**ï¼ˆæœ€æ–°ï¼‰
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

**CUDA 11.8**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**CUDA 11.7**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117
```

#### 4. éªŒè¯å®‰è£…

```bash
python -c "import torch; print('CUDA å¯ç”¨:', torch.cuda.is_available()); print('GPU åç§°:', torch.cuda.get_device_name(0))"
```

**æˆåŠŸè¾“å‡ºç¤ºä¾‹ï¼š**
```
CUDA å¯ç”¨: True
GPU åç§°: NVIDIA GeForce RTX 3060
```

---

### æ–¹æ¡ˆ Bï¼šä½¿ç”¨äº‘ GPUï¼ˆå…è´¹ï¼‰

å¦‚æœä½ çš„ç”µè„‘æ²¡æœ‰ NVIDIA GPUï¼Œå¯ä»¥ä½¿ç”¨äº‘æœåŠ¡ï¼š

#### Google Colabï¼ˆæ¨èï¼Œå…è´¹ï¼‰

1. è®¿é—® [Google Colab](https://colab.research.google.com/)
2. ä¸Šä¼ ä½ çš„é¡¹ç›®æ–‡ä»¶
3. å¯ç”¨ GPUï¼š
   - ç‚¹å‡» "è¿è¡Œæ—¶" â†’ "æ›´æ”¹è¿è¡Œæ—¶ç±»å‹"
   - ç¡¬ä»¶åŠ é€Ÿå™¨é€‰æ‹© "GPU"
4. è¿è¡Œä»£ç 

#### Kaggle Notebooksï¼ˆå…è´¹ï¼‰

1. è®¿é—® [Kaggle](https://www.kaggle.com/)
2. åˆ›å»ºæ–° Notebook
3. å³ä¾§è®¾ç½®ä¸­å¯ç”¨ GPU
4. ä¸Šä¼ ä»£ç è¿è¡Œ

---

## ğŸ› å¸¸è§é—®é¢˜æ’æŸ¥

### é—®é¢˜ 1ï¼šnvidia-smi æ‰¾ä¸åˆ°å‘½ä»¤

**åŸå› **: æ²¡æœ‰å®‰è£… NVIDIA é©±åŠ¨

**è§£å†³**:
1. è®¿é—® [NVIDIA é©±åŠ¨ä¸‹è½½](https://www.nvidia.com/Download/index.aspx)
2. é€‰æ‹©ä½ çš„æ˜¾å¡å‹å·
3. ä¸‹è½½å¹¶å®‰è£…é©±åŠ¨
4. é‡å¯ç”µè„‘

### é—®é¢˜ 2ï¼štorch.cuda.is_available() è¿”å› False

**æ£€æŸ¥æ­¥éª¤**:

1. **ç¡®è®¤é©±åŠ¨å®‰è£…æ­£ç¡®**
   ```bash
   nvidia-smi
   ```
   
2. **ç¡®è®¤å®‰è£…çš„æ˜¯ GPU ç‰ˆæœ¬ PyTorch**
   ```bash
   python -c "import torch; print(torch.__version__)"
   ```
   - å¦‚æœçœ‹åˆ° `+cpu`ï¼Œè¯´æ˜å®‰è£…é”™äº†
   - åº”è¯¥çœ‹åˆ° `+cu118` æˆ– `+cu121`

3. **é‡æ–°å®‰è£…æ­£ç¡®ç‰ˆæœ¬**
   ```bash
   pip uninstall torch torchvision torchaudio
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
   ```

### é—®é¢˜ 3ï¼šCUDA out of memory

**è§£å†³æ–¹æ³•**:

1. **å‡å° batch_size**
   åœ¨ `config.yaml` ä¸­ä¿®æ”¹ï¼š
   ```yaml
   train:
     batch_size: 4  # ä» 16 æ”¹ä¸º 4
   ```

2. **å‡å°æ¨¡å‹å—æ•°**
   ```yaml
   model:
     num_blocks: 16  # ä» 23 æ”¹ä¸º 16
   ```

3. **æ¸…ç† GPU ç¼“å­˜**
   ```python
   import torch
   torch.cuda.empty_cache()
   ```

---

## âœ… éªŒè¯ GPU æ­£å¸¸å·¥ä½œ

è¿è¡Œå®Œæ•´æµ‹è¯•ï¼š
```bash
python test_model.py
```

å¦‚æœ GPU è®¾ç½®æˆåŠŸï¼Œä½ åº”è¯¥çœ‹åˆ°ï¼š
```
============================================================
æµ‹è¯• 3: GPU æ¨ç†æ€§èƒ½
============================================================

GPU: NVIDIA GeForce RTX 3060

æ¨ç†æ€§èƒ½ (256x256 -> 1024x1024):
  è¿è¡Œæ¬¡æ•°: 10
  æ€»æ—¶é—´: 2.345 ç§’
  å¹³å‡æ—¶é—´: 234.50 ms
  FPS: 4.26

GPU æ˜¾å­˜:
  å·²åˆ†é…: 1245.67 MB
  å·²ä¿ç•™: 1536.00 MB
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| ç¡¬ä»¶ | 256x256 æ¨ç†æ—¶é—´ | è®­ç»ƒé€Ÿåº¦ï¼ˆæ¯ epochï¼‰ |
|------|----------------|-------------------|
| CPU (i7) | ~2000 ms | ~2 å°æ—¶ |
| GTX 1060 | ~200 ms | ~20 åˆ†é’Ÿ |
| RTX 3060 | ~100 ms | ~10 åˆ†é’Ÿ |
| RTX 4090 | ~30 ms | ~3 åˆ†é’Ÿ |

---

## ğŸ¯ å¿«é€Ÿè¯Šæ–­è„šæœ¬

åˆ›å»ºä¸€ä¸ªå¿«é€Ÿæ£€æŸ¥è„šæœ¬ï¼š

```python
# check_gpu.py
import torch
import sys

print("="*60)
print("GPU è¯Šæ–­å·¥å…·")
print("="*60)

print(f"\n1. PyTorch ç‰ˆæœ¬: {torch.__version__}")

cuda_available = torch.cuda.is_available()
print(f"2. CUDA å¯ç”¨: {cuda_available}")

if cuda_available:
    print(f"3. CUDA ç‰ˆæœ¬: {torch.version.cuda}")
    print(f"4. GPU æ•°é‡: {torch.cuda.device_count()}")
    for i in range(torch.cuda.device_count()):
        print(f"   - GPU {i}: {torch.cuda.get_device_name(i)}")
    
    # æµ‹è¯• GPU
    try:
        x = torch.randn(1000, 1000).cuda()
        y = x @ x
        print(f"5. GPU è®¡ç®—æµ‹è¯•: âœ… é€šè¿‡")
    except Exception as e:
        print(f"5. GPU è®¡ç®—æµ‹è¯•: âŒ å¤±è´¥ - {e}")
else:
    print("\nâš ï¸ GPU ä¸å¯ç”¨")
    print("\nå¯èƒ½çš„åŸå› :")
    print("  1. æ²¡æœ‰ NVIDIA GPU")
    print("  2. å®‰è£…äº† CPU ç‰ˆæœ¬çš„ PyTorch")
    print("  3. NVIDIA é©±åŠ¨æœªå®‰è£…")
    print("\nè¯·å‚è€ƒ GPU_SETUP_GUIDE.md è§£å†³")
```

è¿è¡Œï¼š
```bash
python check_gpu.py
```

---

## ğŸ’¡ å»ºè®®

### å¦‚æœä½ æœ‰ NVIDIA GPU
- âœ… å¼ºçƒˆå»ºè®®é…ç½® GPU åŠ é€Ÿ
- è®­ç»ƒé€Ÿåº¦æå‡ 10-100 å€
- æ¨ç†é€Ÿåº¦æå‡ 5-20 å€

### å¦‚æœä½ æ²¡æœ‰ NVIDIA GPU
- âœ… ä»å¯ä»¥ä½¿ç”¨é¡¹ç›®ï¼ˆCPU æ¨¡å¼ï¼‰
- âœ… æ¨èä½¿ç”¨ Google Colab å…è´¹ GPU
- âœ… æˆ–ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ¨ç†ï¼ˆCPU å¯æ¥å—ï¼‰

---

éœ€è¦å¸®åŠ©ï¼Ÿè¯·æä¾›ä»¥ä¸‹ä¿¡æ¯ï¼š
1. `nvidia-smi` çš„è¾“å‡º
2. `python -c "import torch; print(torch.__version__)"` çš„è¾“å‡º
3. ä½ çš„æ˜¾å¡å‹å·
