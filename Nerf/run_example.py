"""
NeRF è¿è¡Œç¤ºä¾‹
å¿«é€Ÿå…¥é—¨è„šæœ¬ï¼Œç”Ÿæˆåˆæˆæ•°æ®å¹¶è®­ç»ƒç®€å•çš„ NeRF æ¨¡å‹

è¿è¡Œæ–¹å¼ï¼š
    python run_example.py
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from tqdm import tqdm
import os

from tiny_nerf import TinyNeRF, train_nerf, render_image, get_rays


# ==================== åˆæˆæ•°æ®ç”Ÿæˆ ====================
def generate_synthetic_data(N_images=20, H=100, W=100):
    """
    ç”Ÿæˆç®€å•çš„åˆæˆåœºæ™¯æ•°æ®
    åœºæ™¯ï¼šä¸€ä¸ªå½©è‰²çƒä½“
    
    å‚æ•°:
        N_images: å›¾åƒæ•°é‡
        H, W: å›¾åƒå°ºå¯¸
    
    è¿”å›:
        images: å›¾åƒæ•°æ® [N_images, H, W, 3]
        poses: ç›¸æœºä½å§¿ [N_images, 4, 4]
        focal: ç„¦è·
    """
    print("ğŸ¨ ç”Ÿæˆåˆæˆåœºæ™¯æ•°æ®...")
    
    focal = 100.0  # ç„¦è·
    radius = 4.0   # ç›¸æœºåˆ°åŸç‚¹çš„è·ç¦»
    
    images = []
    poses = []
    
    # ç”Ÿæˆå›´ç»•ç‰©ä½“çš„ç›¸æœºè½¨è¿¹
    for i in range(N_images):
        # ç›¸æœºä½ç½®ï¼ˆåœ†å½¢è½¨è¿¹ï¼‰
        theta = 2.0 * np.pi * i / N_images
        cam_pos = np.array([
            radius * np.cos(theta),
            radius * np.sin(theta),
            0.0
        ])
        
        # æ„å»ºç›¸æœºåˆ°ä¸–ç•Œåæ ‡ç³»çš„å˜æ¢çŸ©é˜µ
        # ç›¸æœºæœå‘åŸç‚¹
        forward = -cam_pos / np.linalg.norm(cam_pos)  # z è½´
        up = np.array([0.0, 0.0, 1.0])                # ä¸–ç•Œ z è½´å‘ä¸Š
        right = np.cross(up, forward)                 # x è½´
        right = right / np.linalg.norm(right)
        up = np.cross(forward, right)                 # é‡æ–°è®¡ç®— y è½´
        
        # ç»„è£…å˜æ¢çŸ©é˜µ
        c2w = np.eye(4)
        c2w[:3, 0] = right
        c2w[:3, 1] = up
        c2w[:3, 2] = forward
        c2w[:3, 3] = cam_pos
        
        poses.append(c2w)
        
        # ç”Ÿæˆå›¾åƒï¼ˆæ¸²æŸ“ä¸€ä¸ªç®€å•çš„çƒä½“ï¼‰
        img = render_synthetic_sphere(H, W, focal, c2w)
        images.append(img)
    
    images = np.stack(images, axis=0)
    poses = np.stack(poses, axis=0)
    
    print(f"  âœ“ ç”Ÿæˆ {N_images} å¼  {H}x{W} å›¾åƒ")
    
    return torch.from_numpy(images).float(), torch.from_numpy(poses).float(), focal


def render_synthetic_sphere(H, W, focal, c2w):
    """
    æ¸²æŸ“ä¸€ä¸ªå½©è‰²çƒä½“ï¼ˆä½œä¸ºè®­ç»ƒæ•°æ®ï¼‰
    
    å‚æ•°:
        H, W: å›¾åƒå°ºå¯¸
        focal: ç„¦è·
        c2w: ç›¸æœºåˆ°ä¸–ç•Œå˜æ¢çŸ©é˜µ
    
    è¿”å›:
        img: æ¸²æŸ“çš„å›¾åƒ [H, W, 3]
    """
    img = np.ones((H, W, 3))  # ç™½è‰²èƒŒæ™¯
    
    # çƒä½“å‚æ•°
    sphere_center = np.array([0.0, 0.0, 0.0])
    sphere_radius = 1.0
    
    # ç›¸æœºå‚æ•°
    cam_pos = c2w[:3, 3]
    
    # éå†æ¯ä¸ªåƒç´ 
    for i in range(H):
        for j in range(W):
            # è®¡ç®—å…‰çº¿æ–¹å‘ï¼ˆç›¸æœºåæ ‡ç³»ï¼‰
            x = (j - W * 0.5) / focal
            y = -(i - H * 0.5) / focal
            z = -1.0
            
            ray_dir_cam = np.array([x, y, z])
            
            # è½¬æ¢åˆ°ä¸–ç•Œåæ ‡ç³»
            ray_dir = c2w[:3, :3] @ ray_dir_cam
            ray_dir = ray_dir / np.linalg.norm(ray_dir)
            
            # å…‰çº¿-çƒä½“ç›¸äº¤æ£€æµ‹
            oc = cam_pos - sphere_center
            a = np.dot(ray_dir, ray_dir)
            b = 2.0 * np.dot(oc, ray_dir)
            c = np.dot(oc, oc) - sphere_radius * sphere_radius
            discriminant = b * b - 4 * a * c
            
            if discriminant > 0:
                # ç›¸äº¤ï¼Œè®¡ç®—äº¤ç‚¹
                t = (-b - np.sqrt(discriminant)) / (2.0 * a)
                if t > 0:
                    # è®¡ç®—äº¤ç‚¹ä½ç½®å’Œæ³•å‘é‡
                    hit_point = cam_pos + t * ray_dir
                    normal = (hit_point - sphere_center) / sphere_radius
                    
                    # ç®€å•çš„ç€è‰²ï¼ˆåŸºäºæ³•å‘é‡ï¼‰
                    color = (normal + 1.0) * 0.5  # æ˜ å°„åˆ° [0, 1]
                    img[i, j] = color
    
    return img


# ==================== ä¸»ç¨‹åº ====================
def main():
    """ä¸»ç¨‹åºï¼šç”Ÿæˆæ•°æ®ã€è®­ç»ƒæ¨¡å‹ã€æ¸²æŸ“ç»“æœ"""
    
    print("=" * 60)
    print("ğŸš€ NeRF è®­ç»ƒç¤ºä¾‹")
    print("=" * 60)
    
    # -------------------- é…ç½®å‚æ•° --------------------
    # æ•°æ®å‚æ•°
    N_train_images = 20      # è®­ç»ƒå›¾åƒæ•°é‡
    H, W = 100, 100         # å›¾åƒå°ºå¯¸ï¼ˆè¾ƒå°ä»¥åŠ å¿«é€Ÿåº¦ï¼‰
    
    # æ¨¡å‹å‚æ•°
    pos_L = 6               # ä½ç½®ç¼–ç çº§åˆ«ï¼ˆè¶Šå¤§è¶Šç²¾ç»†ï¼‰
    dir_L = 4               # æ–¹å‘ç¼–ç çº§åˆ«
    hidden_dim = 128        # éšè—å±‚ç»´åº¦
    use_viewdir = True      # æ˜¯å¦ä½¿ç”¨è§‚å¯Ÿæ–¹å‘
    
    # è®­ç»ƒå‚æ•°
    epochs = 500            # è®­ç»ƒè½®æ•°ï¼ˆå¢åŠ å¯æé«˜è´¨é‡ï¼‰
    batch_size = 1024       # æ¯æ‰¹å…‰çº¿æ•°
    lr = 5e-4               # å­¦ä¹ ç‡
    
    # è®¾å¤‡è®¾ç½®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nğŸ’» ä½¿ç”¨è®¾å¤‡: {device}")
    
    if device.type == 'cpu':
        print("   âš ï¸  å»ºè®®ä½¿ç”¨ GPU ä»¥åŠ å¿«è®­ç»ƒé€Ÿåº¦")
    
    # -------------------- ç”Ÿæˆæ•°æ® --------------------
    images, poses, focal = generate_synthetic_data(N_train_images, H, W)
    
    print(f"\nğŸ“Š æ•°æ®ä¿¡æ¯:")
    print(f"  - å›¾åƒæ•°é‡: {images.shape[0]}")
    print(f"  - å›¾åƒå°ºå¯¸: {H} x {W}")
    print(f"  - ç„¦è·: {focal}")
    print(f"  - æ€»åƒç´ æ•°: {images.shape[0] * H * W:,}")
    
    # -------------------- åˆ›å»ºæ¨¡å‹ --------------------
    print("\nğŸ—ï¸  åˆ›å»º NeRF æ¨¡å‹...")
    model = TinyNeRF(
        pos_L=pos_L,
        dir_L=dir_L,
        hidden_dim=hidden_dim,
        use_viewdir=use_viewdir
    )
    
    n_params = sum(p.numel() for p in model.parameters())
    print(f"  âœ“ æ¨¡å‹å‚æ•°æ•°é‡: {n_params:,}")
    
    # -------------------- è®­ç»ƒæ¨¡å‹ --------------------
    print(f"\nğŸ“ å¼€å§‹è®­ç»ƒ (å…± {epochs} è½®)...")
    print("   è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")
    
    losses = train_nerf(
        model=model,
        images=images,
        poses=poses,
        focal=focal,
        H=H,
        W=W,
        epochs=epochs,
        batch_size=batch_size,
        lr=lr,
        device=device,
        verbose=True
    )
    
    print("  âœ“ è®­ç»ƒå®Œæˆï¼")
    
    # -------------------- å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ --------------------
    print("\nğŸ“ˆ ä¿å­˜è®­ç»ƒæ›²çº¿...")
    output_dir = Path("output")
    output_dir.mkdir(exist_ok=True)
    
    plt.figure(figsize=(10, 5))
    plt.plot(losses)
    plt.xlabel('Epoch')
    plt.ylabel('Loss (MSE)')
    plt.title('NeRF Training Loss')
    plt.grid(True, alpha=0.3)
    plt.yscale('log')
    training_plot_path = output_dir / "training_loss.png"
    plt.savefig(training_plot_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  âœ“ è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {training_plot_path}")
    
    # -------------------- æ¸²æŸ“æµ‹è¯•è§†è§’ --------------------
    print("\nğŸ¬ æ¸²æŸ“æµ‹è¯•è§†è§’...")
    
    # é€‰æ‹©å‡ ä¸ªæµ‹è¯•è§†è§’
    test_indices = [0, N_train_images // 4, N_train_images // 2, 3 * N_train_images // 4]
    
    fig, axes = plt.subplots(2, len(test_indices), figsize=(15, 7))
    
    for idx, test_idx in enumerate(test_indices):
        # æ¸²æŸ“
        test_pose = poses[test_idx]
        rendered_img = render_image(
            model=model,
            pose=test_pose,
            H=H,
            W=W,
            focal=focal,
            device=device,
            chunk=512
        )
        
        # æ˜¾ç¤ºçœŸå®å›¾åƒ
        axes[0, idx].imshow(images[test_idx].numpy())
        axes[0, idx].set_title(f'Ground Truth (View {test_idx})')
        axes[0, idx].axis('off')
        
        # æ˜¾ç¤ºæ¸²æŸ“å›¾åƒ
        axes[1, idx].imshow(rendered_img.numpy())
        axes[1, idx].set_title(f'NeRF Render (View {test_idx})')
        axes[1, idx].axis('off')
    
    plt.tight_layout()
    comparison_path = output_dir / "render_comparison.png"
    plt.savefig(comparison_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  âœ“ å¯¹æ¯”å›¾å·²ä¿å­˜: {comparison_path}")
    
    # -------------------- æ¸²æŸ“æ–°è§†è§’ --------------------
    print("\nğŸ†• æ¸²æŸ“å…¨æ–°è§†è§’ï¼ˆæ¨¡å‹æœªè§è¿‡çš„è§’åº¦ï¼‰...")
    
    # ç”Ÿæˆä¸€ä¸ªæ–°çš„ç›¸æœºä½ç½®
    theta_new = np.pi / 3  # 60 åº¦
    radius = 4.0
    cam_pos_new = np.array([
        radius * np.cos(theta_new),
        radius * np.sin(theta_new),
        0.5  # ç¨å¾®å‘ä¸Š
    ])
    
    # æ„å»ºå˜æ¢çŸ©é˜µ
    forward = -cam_pos_new / np.linalg.norm(cam_pos_new)
    up = np.array([0.0, 0.0, 1.0])
    right = np.cross(up, forward)
    right = right / np.linalg.norm(right)
    up = np.cross(forward, right)
    
    c2w_new = np.eye(4)
    c2w_new[:3, 0] = right
    c2w_new[:3, 1] = up
    c2w_new[:3, 2] = forward
    c2w_new[:3, 3] = cam_pos_new
    
    pose_new = torch.from_numpy(c2w_new).float()
    
    # æ¸²æŸ“
    novel_img = render_image(
        model=model,
        pose=pose_new,
        H=H,
        W=W,
        focal=focal,
        device=device,
        chunk=512
    )
    
    plt.figure(figsize=(8, 8))
    plt.imshow(novel_img.numpy())
    plt.title('Novel View Synthesis (æ–°è§†è§’åˆæˆ)')
    plt.axis('off')
    novel_path = output_dir / "novel_view.png"
    plt.savefig(novel_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  âœ“ æ–°è§†è§’æ¸²æŸ“å·²ä¿å­˜: {novel_path}")
    
    # -------------------- å®Œæˆ --------------------
    print("\n" + "=" * 60)
    print("âœ… å…¨éƒ¨å®Œæˆï¼")
    print("=" * 60)
    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶ä½ç½®: {output_dir.absolute()}")
    print(f"  - {training_plot_path.name}: è®­ç»ƒæŸå¤±æ›²çº¿")
    print(f"  - {comparison_path.name}: çœŸå® vs æ¸²æŸ“å¯¹æ¯”")
    print(f"  - {novel_path.name}: æ–°è§†è§’åˆæˆç»“æœ")
    
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥å¯ä»¥å°è¯•:")
    print("  1. å¢åŠ è®­ç»ƒè½®æ•° (epochs) ä»¥æé«˜è´¨é‡")
    print("  2. å¢åŠ å›¾åƒåˆ†è¾¨ç‡ (H, W) è·å¾—æ›´ç²¾ç»†çš„ç»“æœ")
    print("  3. è°ƒæ•´æ¨¡å‹å‚æ•° (hidden_dim, pos_L) æ”¹å˜å®¹é‡")
    print("  4. ä½¿ç”¨çœŸå®æ•°æ®é›†ï¼ˆå¦‚ NeRF Synthetic Datasetï¼‰")
    
    print("\nğŸ“š å­¦ä¹ å»ºè®®:")
    print("  - é˜…è¯» tiny_nerf.py ä¸­çš„ä»£ç å’Œæ³¨é‡Š")
    print("  - ç†è§£ä½ç½®ç¼–ç ã€ä½“ç§¯æ¸²æŸ“çš„ä½œç”¨")
    print("  - å°è¯•å¯è§†åŒ–ä¸­é—´ç»“æœï¼ˆå¯†åº¦åœºã€é¢œè‰²åœºç­‰ï¼‰")
    
    print("\nğŸ‰ ç¥ä½ å­¦ä¹ æ„‰å¿«ï¼")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        print("\nğŸ’¡ å¦‚éœ€å¸®åŠ©ï¼Œè¯·æ£€æŸ¥ README.md æˆ–æ issue")
